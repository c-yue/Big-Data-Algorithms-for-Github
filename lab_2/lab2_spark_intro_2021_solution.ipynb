{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "name": "BE4-Spark.ipynb",
    "colab": {
      "name": "lab2_spark_intro_2021_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NG9OG1Z6aJQ"
      },
      "source": [
        "<h1><center>Big Data Algorithms Techniques & Platforms</center></h1>\n",
        "\n",
        "<h2>\n",
        "<hr style=\" border:none; height:3px;\">\n",
        "<center>Lab 2: Introduction to Spark</center>\n",
        "<hr style=\" border:none; height:3px;\">\n",
        "</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBwajlZM6aJQ"
      },
      "source": [
        "# A. Introduction\n",
        "\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "In this little set of exercises you'll learn basic Spark programming skills that are necessary to develop simple, yet powerful, applications to be executed in a distributed environment.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "The assignment is presented in this __Jupyter Notebook__, an interface that offers support for text, code, images and other media. Essentially, a Jupyter Notebook consists of multiple _cells_, either containing some text, like the one that you are reading, or code that you can execute. \n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "The cells that contain code are marked with the label \"In [  ]\" that is found on the left of the cell. In order to execute the code in the cell, you need to select the cell and press Shift+Enter (hold Shift while pressing Enter). During the execution of the code, the label on the left of the cell will change to \"In [ * ]\"; when the execution is over, the asterisk is replaced by a number. \n",
        "</font>  \n",
        "    \n",
        "<font size=\"2\">\n",
        "IMPORTANT: wait for the execution of the cell to be over before proceeding in the Notebook. \n",
        "</font>\n",
        "<font size=\"3\">\n",
        "Whenever you define a variable or a function in a cell, that variable and function will be visible in the cells below. \n",
        "This means that one can split the code of an application across different cells to interleave it with textual explanations.\n",
        "    </font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Spark supports four programming languages: Scala (the one used to implement Spark itself), Java, R and Python. In this assignment we use Python.\n",
        "The assignment will guide you through the Spark programming notions by using simple examples. \n",
        "After the examples, the exercises will give you the chance to practice those notions.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "**Apache Spark** is a cluster computing framework for parallel data processing that was conceived to address the inefficiencies of Hadoop with respect to iterative computations. \n",
        "Spark is used by both data scientists, who analyze large datasets, and engineers, who develop data processing applications. Spark allows both to concentrate on their application by hiding all the complexity of running applications in a distributed environment: distributed systems programming, network communication and fault tolerance.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "In order to run a distributed computation on Spark, one has to develop a **Spark application**.\n",
        "A Spark application runs as a set of independent processes (called the _Executors_) across the machines (a.k.a., _Worker_ nodes) of a cluster, coordinated by the _Driver_, the process that runs the $main()$ function of the application.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "The _Driver_ creates an object called _SparkContext_ that communicates with the underlying cluster manager and coordinates the distribution of the computation across the _Executors_.\n",
        "For example, if we were running an application to count the number of lines in a file, \n",
        "different machines might count lines in different ranges of the file. \n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<hr style=\" border:none; height:2px;\">\n",
        " <font  size=\"3\" color='#91053d'>**Execute the following cell in order to initialize the _SparkContext_.**</font>\n",
        "<hr style=\" border:none; height:2px;\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enV8P94A6cEi"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz\n",
        "!tar zxvf spark-3.0.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.3-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkConf, SparkContext\n",
        "conf = SparkConf().setMaster(\"local\")\n",
        "sc = SparkContext(conf = conf)\n",
        "print(\"initialization successful!\")\n",
        "\n",
        "import numpy as np\n",
        "import random as rn\n",
        "\n",
        "seed_value=0\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHqO_GdVavyn"
      },
      "source": [
        "## A.1 Resilient Distributed Dataset (RDD)\n",
        "\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Spark distributes the data and the computations across the machines of a cluster by using the notion of **Resilient Distributed Dataset (RDD)**. \n",
        "An RDD is an **immutable** distributed collection of data. \n",
        "Each element of an RDD can be an instance of any Python type, including a user-defined class.\n",
        "The _SparkContext_  splits an RDD into multiple _partitions_ and scatters them across different machines of the cluster. \n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "The distribution of the partitions of an RDD is completely transparent to the application.\n",
        "The only thing a Spark application has to do is to create some RDDs and \n",
        "specify the computations on these RDDs, by using special functions that Spark provides to this purpose. \n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzuUNBSv6aJT"
      },
      "source": [
        "### Creating RDDs\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Spark provides two ways to create an RDD:\n",
        "\n",
        "<ul>\n",
        "<li> By distributing a collection of objects.\n",
        "<li> By loading an external dataset (either in a file or a database).\n",
        "</ul>\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<hr style=\"border:2px solid;\">\n",
        "\n",
        "<p>\n",
        "<font size=\"3\" color='#91053d'><strong>Execute the following code to create an RDD called $words$, where each element is a string taken from the list $wordList$.</strong></font>\n",
        "</p>\n",
        "<hr style=\"border:2px solid;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": "json-false",
        "ein.tags": [
          "worksheet-0"
        ],
        "scrolled": true,
        "id": "HMSUe1Z66aJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec348c65-6417-489f-8b64-2251f64d7844"
      },
      "source": [
        "wordList = [\"Al\", \"Ani\", \"Jackie\", \"Lalitha\", \"Mark\", \"Neil\", \"Nick\", \"Shirin\", \"Jackie\", \"Mark\", \"Ani\", \"Mark\"]\n",
        "words = sc.parallelize(wordList)\n",
        "print(\"Done!\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": [
          "worksheet-0"
        ],
        "id": "Bp6vVZWH6aJW"
      },
      "source": [
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Once created, Spark provides two types of  operations on a RDD:\n",
        "<ol>\n",
        "<li> **Transformations**. A transformation takes in one or more RDDs and returns a new RDD.\n",
        "<li> **Actions**. An action takes in an RDD and outputs a value.\n",
        "</ol>\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "One common transformation is filtering data that matches a predicate by using the function $filter$.\n",
        "The function $filter$ is applied on an RDD and takes in a predicate.\n",
        "It loops through each element of the RDD and verifies whether that element satisfies the predicate. The function $filter$ outputs a new RDD whose elements are those that satisfy the predicate.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<hr style=\" border:2px solid;\">\n",
        "<p>\n",
        "\n",
        " <font size=\"3\" color='#91053d'>**Execute the following code to create an RDD called $nNames$ by retaining only the names whose first letter is 'N' from the RDD $words$ .**</font>\n",
        "\n",
        "</p>\n",
        "<hr style=\" border:2px solid;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYkR-scr6aJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491a59aa-93ab-4ec9-acf9-95445b9f26e9"
      },
      "source": [
        "'''\n",
        "As mentioned before, the function filter takes in a predicate that is itself a function (returning a boolean value).\n",
        "An elegant way to pass a function to a function in Python is the lambda notation.\n",
        "\n",
        "In the code below, the argument of the function filter is a function that takes in a variable called \n",
        "\"name\"; the type of this variable must match the type of the elements of the RDD words, in this case \n",
        "a string.\n",
        "Then the function returns whether the first character of the string \"name\" is N. \n",
        "\n",
        "Another way to express the same thing without the lambda notation would be to explicitly define the predicate, \n",
        "as follows:\n",
        "\n",
        "def predicate(name):\n",
        "    return name[:1]=='N'\n",
        "\n",
        "nNames = words.filter(predicate)\n",
        "\n",
        "'''\n",
        "nNames = words.filter(lambda name: name[:1]=='N') \n",
        "print(\"done!\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-ifOvsg6aJY"
      },
      "source": [
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "The transformation $filter$ above is not executed by Spark until an action is called on the RDD $nNames$.\n",
        "In general, Spark postpones the execution of a transformation on a RDD to when an action is invoked on the RDD itself. This is called **lazy evaluation**. The reason for this approach will be clearer in the next example.\n",
        "    </font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "One example of action is the function $first()$ that returns the first element in the RDD.\n",
        "    </font>\n",
        "</p>\n",
        "\n",
        "<hr style=\" border:2px solid;\">\n",
        "<p>\n",
        " <font size=\"3\" color='#91053d'><strong>Execute the following code to print the first element of the RDD $nNames$.</strong></font>\n",
        "</p>\n",
        "<hr style=\" border:2px solid;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck-2pfIu6aJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebe7bdc2-8f14-4f3e-ebb4-cbc66a9e6fd8"
      },
      "source": [
        "'''\n",
        "REMEMBER: the variable nNames has been defined in the cell above, so \n",
        "it is VISIBLE in this cell as well as in the cells below the current one\n",
        "'''\n",
        "print(nNames.first())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neil\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA4ty9jh6aJb"
      },
      "source": [
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "The previous example clearly shows that a Spark application is essentially a sequence of operations that create, transform and perform some actions on RDDs.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "The following code shows an example of creation of RDD from an external dataset, more precisely a text file that contains log information of a Neo4j database. \n",
        "The function $textFile()$ takes in the path to the input text file and returns an RDD, where each element is a line of the file.\n",
        "The code goes through the following steps:\n",
        "\n",
        "<ol>\n",
        "<li> **RDD creation**. Creates a RDD called $lines$, where each element is a line from the input text file.\n",
        "<li> **Transformation filter**. Creates a RDD called $exceptions$ from the RDD $lines$ by only retaining the lines containing the string \"exception\".\n",
        "<li> **Action count()**. Counts the number of elements of the RDD $exceptions$. \n",
        "<li> **Action take**. Prints the first line of the RDD $exceptions$. \n",
        "</ol>\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Here we can see the advantage of the _lazy evaluation_ of transformations. \n",
        "Spark does not execute the function $textFile()$ as soon as it is invoked, which would result\n",
        "in loading into main memory the whole content of the log file (it can be very large). \n",
        "Instead, it waits until the first action $count()$ is invoked.\n",
        "Since this action is called on a filtered version of the RDD $lines$, \n",
        "Spark will load into memory only the lines that contain the word \"exception\".\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<hr style=\" border:2px solid;\">\n",
        "<p>\n",
        " <font size=\"3\" color='#91053d'><strong>Execute the following code.</strong></font>\n",
        "</p>\n",
        "<hr style=\" border:2px solid;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": "json-false",
        "ein.tags": [
          "worksheet-0"
        ],
        "id": "jn9z61M86aJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce947e97-27bb-42e6-b860-228c91eb322e"
      },
      "source": [
        "data_file = \"neo4j.log\"\n",
        "\n",
        "# 1. RDD creation\n",
        "lines = sc.textFile(data_file)\n",
        "\n",
        "#2. RDD filter\n",
        "exceptions = lines.filter(lambda line : \"exception\" in line)\n",
        "\n",
        "#3. Action count()\n",
        "nbLines = exceptions.count()\n",
        "print(\"Number of exception lines \", nbLines)\n",
        "\n",
        "'''\n",
        "IMPORTANT: The output shows the first line of the log file that contains \n",
        "words such as \"ERROR\" and \"failed\".\n",
        "This does not mean that Spark is raising an error; \n",
        "it is just showing the content of the input file.\n",
        "So everything's fine :)\n",
        "'''\n",
        "\n",
        "#4. Print first line.\n",
        "exceptions.take(1)\n",
        "\n",
        "#Here the text will visualize the content of the log file that contain a text starting with an error code:\n",
        "\n",
        "#['2017-10-06 13:12:26.097+0000 ERROR Failed to start Neo4j: Starting Neo4j failed: Component \\'org.neo4j.server.database.\n",
        "#LifecycleManagingDatabase@2814f71a\\' was successfully initialized, but failed to start. Please see the attached c ...\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of exception lines  5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2017-10-06 13:12:26.097+0000 ERROR Failed to start Neo4j: Starting Neo4j failed: Component \\'org.neo4j.server.database.LifecycleManagingDatabase@2814f71a\\' was successfully initialized, but failed to start. Please see the attached cause exception \"Format version is not supported (resource BufferedChecksumIndexInput(MMapIndexInput(path=\"/Users/quercini_gia/Documents/software/neo4j-community-3.2.5/data/databases/social-network/upgrade/index/lucene/relationship/crosslinks/segments_1\"))): -11 (needs to be between 1071082519 and 1071082519). This version of Lucene only supports indexes created with release 4.0 and later.\". Starting Neo4j failed: Component \\'org.neo4j.server.database.LifecycleManagingDatabase@2814f71a\\' was successfully initialized, but failed to start. Please see the attached cause exception \"Format version is not supported (resource BufferedChecksumIndexInput(MMapIndexInput(path=\"/Users/quercini_gia/Documents/software/neo4j-community-3.2.5/data/databases/social-network/upgrade/index/lucene/relationship/crosslinks/segments_1\"))): -11 (needs to be between 1071082519 and 1071082519). This version of Lucene only supports indexes created with release 4.0 and later.\".']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": [
          "worksheet-0"
        ],
        "id": "ZYI-SZW16aJd"
      },
      "source": [
        "## A.2 Transformations\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Here are some common transformations in Spark. \n",
        "In the following list, $r$ denotes the RDD on which the transformation is invoked.\n",
        "<ol>\n",
        "<li> $r.filter(pred)$. Returns a RDD consisting of only the elements of the input RDD $r$ that satisfy the given predicate.\n",
        "<li> $r.map(func)$. Applies a function $func$ to each element of the input RDD $r$ and returns an RDD of the result.\n",
        "<li> $r.flatMap(func)$. Same as $map()$, but used when $map()$ would return a RDD where each element is a list.\n",
        "<li> $r.union(other)$. Takes in two RDDs ($r$ and $other$) and returns a RDD that contains the elements from both. Unlike the mathematical operation, $union$ in Spark does not remove the duplicates.\n",
        "<li> $r.intersection(other)$. Takes in two RDDs ($r$ and $other$) and returns a RDD that contains the elements found in both.\n",
        "<li> $r.subtract(other)$. Takes in two RDDs ($r$ and $other$) and returns a RDD that contains the elements from the RDD $r$, except those that are found in $other$.\n",
        "<li> $r.cartesian(other)$. Takes in two RDDs ($r$ and $other$) and returns a RDD that contains the Cartesian product of both.\n",
        "<li> $r.distinct()$. Returns a RDD that contains the same elements as the input RDD $r$ without duplicates.\n",
        "</ol>\n",
        "    \n",
        "We are now going to look at an example of use of these transformations.\n",
        "</font>    \n",
        "</p>\n",
        "\n",
        "<hr style=\" border:2px solid;\">\n",
        "<p>\n",
        " <font size=\"3\" color='#91053d'><strong>Execute the following code to create the two RDDs $r1$ and $r2$</strong></font>\n",
        "</p>\n",
        "<hr style=\" border:2px solid;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZu-MV666aJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07dabd0-e1e8-41a4-b455-620cf8c45c48"
      },
      "source": [
        "r1 = sc.parallelize([1, 2, 3, 4])\n",
        "r2 = sc.parallelize([3, 4, 5, 6, 7])\n",
        "print(\"done\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52BMdqm86aJg"
      },
      "source": [
        "### Use of $map()$\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Here we see an example of the transformation $map()$.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<hr style=\" border:2px solid;\">\n",
        "<p>\n",
        "<font size=\"3\" color='#91053d'>**Execute the following code to create:\n",
        " <ol>\n",
        " <li> a RDD $square$, where each element is the square of the corresponding element in $r1$; \n",
        " <li> a RDD $half$, where each element is the half of the corresponding element in $r2$.**\n",
        " </ol>\n",
        " </font>\n",
        "</p>\n",
        "<hr style=\" border:2px solid;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE0O6bg16aJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1bb4cf-69da-4909-c43c-e3a61c8297e2"
      },
      "source": [
        "square = r1.map(lambda x : x*x)\n",
        "half = r2.map(lambda x: x/2)\n",
        "\n",
        "# The function collect() is an action that transforms the RDD into a Python list that can be printed.\n",
        "print(\"Elements of RDD square \", square.collect())\n",
        "print(\"Elements of the RDD half \", half.collect())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements of RDD square  [1, 4, 9, 16]\n",
            "Elements of the RDD half  [1.5, 2.0, 2.5, 3.0, 3.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRFQ-Cn76aJj"
      },
      "source": [
        "### Use of $flatMap()$\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "The transformation $flatMap()$ works by applying the transformation $map()$ on the input RDD; \n",
        "if each element of the resulting RDD is a list, $flatMap()$ returns a RDD where all lists are merged.\n",
        "In other words, when $map()$ returns a RDD where each element is a list, $flatMap()$ returns a RDD where each element is a value of that list.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Let's see an example. Suppose that we want to return a RDD from $r1$ where each element is associated to its square. \n",
        "More precisely, the output RDD will be as follows:\n",
        "<center>\n",
        "[ [1, 1], [2, 4], [3, 9], [4, 16] ]\n",
        "</center>\n",
        "</font>    \n",
        "</p>\n",
        "\n",
        "<hr style=\" border:solid 2px;\">\n",
        "<p>\n",
        "\n",
        " <font size=\"3\" color='#91053d'>**Execute the following code to create a RDD $squares$ where each element of $r1$ is associated to its square.**</font>\n",
        "</p>\n",
        "<hr style=\" border:solid 2px;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA1xO3B96aJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad65aed6-d021-4d99-fcf7-f6104ae6df99"
      },
      "source": [
        "squares = r1.map(lambda x : [x, x*x])\n",
        "print(\"Elements of RDD squares \", squares.collect())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements of RDD squares  [[1, 1], [2, 4], [3, 9], [4, 16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d-9F8AF6aJl"
      },
      "source": [
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "\n",
        "As you can see, each element of the RDD $squares$ is a list of two elements; indeed, \n",
        "after calling the action $collect()$, we obtain a list of lists in Python. \n",
        "If, instead, we want a simple list of elements, we have to invoke $flatMap()$ on $r1$.\n",
        "More precisely, with $flatMap()$ we obtain the following RDD:\n",
        "<center>\n",
        "[1, 1, 2, 4, 3, 9, 4, 16]\n",
        "</center>\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<hr style=\" border:solid 2px;\">\n",
        "<p>\n",
        "\n",
        " <font size=\"3\" color='#91053d'><strong>Execute the following code to create an RDD $squares$ where each element of $r1$ is associated to its square (but each element is just a value instead of a list of values</strong></font>\n",
        "</p>\n",
        "<hr style=\" border:solid 2px;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzZSQT5x6aJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b08289-e10f-45a3-e1f2-9151ac5444cf"
      },
      "source": [
        "squares = r1.flatMap(lambda x : [x, x*x])\n",
        "print(\"Elements of RDD squares \", squares.collect())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements of RDD squares  [1, 1, 2, 4, 3, 9, 4, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i1Mi0F26aJn"
      },
      "source": [
        "### Use of set transformations\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "The set transformations are $union$, $intersection$, $subtract$ and $cartesian$.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<hr style=\" border:solid 2px;\">\n",
        "<p>\n",
        " <font size=\"3\" color='#91053d'>**Execute the following code to see an example of these transformations**</font>\n",
        "</p>\n",
        "<hr style=\" border:solid 2px;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq51szgV6aJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec533a8-c7b7-493f-b097-63119571b748"
      },
      "source": [
        "union = r1.union(r2)\n",
        "intersection = r1.intersection(r2)\n",
        "subtract = r1.subtract(r2)\n",
        "cartesian = r1.cartesian(r2)\n",
        "\n",
        "print(\"Elements of RDD r1 \", r1.collect())\n",
        "print(\"Elements of RDD r2 \", r2.collect())\n",
        "print(\"Elements of RDD union \", union.collect())\n",
        "print(\"Elements of RDD intesection \", intersection.collect())\n",
        "print(\"Elements of RDD subtract \", subtract.collect())\n",
        "print(\"Elements of RDD cartesian \", cartesian.collect())\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements of RDD r1  [1, 2, 3, 4]\n",
            "Elements of RDD r2  [3, 4, 5, 6, 7]\n",
            "Elements of RDD union  [1, 2, 3, 4, 3, 4, 5, 6, 7]\n",
            "Elements of RDD intesection  [4, 3]\n",
            "Elements of RDD subtract  [2, 1]\n",
            "Elements of RDD cartesian  [(1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (3, 3), (3, 4), (3, 5), (3, 6), (3, 7), (4, 3), (4, 4), (4, 5), (4, 6), (4, 7)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3jFWhJu6aJq"
      },
      "source": [
        "### Use of $distinct()$\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "The transformation $distinct()$ returns an RDD that contains the same elements as the input RDD without the duplicates.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<hr style=\" border:solid 2px;\">\n",
        "<p>\n",
        "<font size=\"3\" color='#91053d'><strong>Execute the following code to see an example of use of $distinct()$</strong></font>\n",
        "</p>\n",
        "<hr style=\" border:solid 2px;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d75wgAdh6aJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582f2402-9ecf-41d7-f860-d72a9c9c1c3a"
      },
      "source": [
        "nodup = union.distinct()\n",
        "print(\"Elements of the RDD union: \", union.collect())\n",
        "print(\"Elements of the RDD union (with no duplicates): \", nodup.collect())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements of the RDD union:  [1, 2, 3, 4, 3, 4, 5, 6, 7]\n",
            "Elements of the RDD union (with no duplicates):  [2, 4, 6, 1, 3, 5, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": [
          "worksheet-0"
        ],
        "id": "Xvn2Sbqp6aJt"
      },
      "source": [
        "## A.3 Actions\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Here are some common actions in Spark. \n",
        "As with transformations, $r$ denotes the RDD on which the action is invoked.\n",
        "\n",
        "<ol>\n",
        "<li> $r.reduce(func)$. Performs a pair-wise application of the given function $func$ to the elements of the input RDD $r$.\n",
        "<li> $r.collect()$. Returns a Python list with all the elements of the input RDD $r$.\n",
        "<li> $r.count()$. Returns the number of elements in the input RDD $r$.\n",
        "<li> $r.countByValue()$. Returns the number of times each element occurs in the input RDD $r$.\n",
        "<li> $r.take(num)$. Prints the first $num$ elements of the input RDD $r$.\n",
        "<li> $r.top(num)$. Prints the top $num$ elements of the input RDD $r$ (sorted in decreasing order).\n",
        "</ol>\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyJB6x1d6aJt"
      },
      "source": [
        "### Use of $reduce(func)$\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "The action $reduce(func)$ performs a pair-wise application of the given function $func$ on the elements of the input RDD. \n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<hr style=\" border:solid 2px;\">\n",
        "<p>\n",
        "<font size=\"3\" color='#91053d'><strong>Execute the following code to sum all values of the RDD $r1$</strong></font>\n",
        "</p>\n",
        "<hr style=\" border:solid 2px;\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwTi7aI06aJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648b50b7-ef0c-4c88-88f1-8fda19a203ed"
      },
      "source": [
        "'''\n",
        "The function passed to the reduce MUST take in two arguments \n",
        "that have the same type as the elements of the input RDD\n",
        "'''\n",
        "sum = r1.reduce(lambda x, y : x + y)\n",
        "print(\"Elements of the RDD r1 \", r1.collect())\n",
        "print(\"Sum of the elements of the RDD r1: \", sum)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements of the RDD r1  [1, 2, 3, 4]\n",
            "Sum of the elements of the RDD r1:  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST2VbA386aJw"
      },
      "source": [
        "### Use of $countByValue()$\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "The action $countByValue()$ counts the number of the occurrences of each element of the input RDD.\n",
        "The result is a Python dictionary, where a key is an element of the input RDD and the corresponding value the number of its occurrences.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<hr style=\" border:solid 2px;\">\n",
        "<p>\n",
        "\n",
        "<font size=\"3\" color='#91053d'>**Execute the following code to get the number of occurrences of each element in the RDD $union$**</font>\n",
        "\n",
        "</p>\n",
        "<hr style=\" border:solid 2px;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfbUnLJm6aJw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26301177-4659-45e0-a8b0-4e0dd0738aca"
      },
      "source": [
        "occurrences = union.countByValue()\n",
        "print(\"Elements of the RDD union \", union.collect())\n",
        "print(\"Occurrences of each element in the RDD union:\")\n",
        "for k, v in occurrences.items():\n",
        "    print(k, \" --> \",  v, \" occurrences\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements of the RDD union  [1, 2, 3, 4, 3, 4, 5, 6, 7]\n",
            "Occurrences of each element in the RDD union:\n",
            "1  -->  1  occurrences\n",
            "2  -->  1  occurrences\n",
            "3  -->  2  occurrences\n",
            "4  -->  2  occurrences\n",
            "5  -->  1  occurrences\n",
            "6  -->  1  occurrences\n",
            "7  -->  1  occurrences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_8pNaIG6aJy"
      },
      "source": [
        "# B Pair RDDs \n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Pair RDDs are simply RDDs where each element is a key-value pair. \n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "We are now going to look at examples of  transformations and actions on pair RDDs.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTc2eNol6aJy"
      },
      "source": [
        "## B.1 Creation of Pair RDDs\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "One common way to create a pair RDD is to transform an existing RDD with a $map()$. \n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<hr style=\" border:solid 2px;\">\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\" color='#91053d'><strong>Execute the following code to create a Pair RDD $kvwords$ from the RDD $words$. Each element of $kvwords$ is a pair where the key is a word and the value is 1</strong></font>\n",
        "</p>\n",
        "<hr style=\" border:solid 2px;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RATemCkH6aJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd3e8e2f-4c01-429e-e20a-4cef670f8173"
      },
      "source": [
        "kvwords = words.map(lambda word : (word, 1))\n",
        "print(kvwords.take(5))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Al', 1), ('Ani', 1), ('Jackie', 1), ('Lalitha', 1), ('Mark', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY7-8vfr6aJ1"
      },
      "source": [
        "## B.2 Transformations on Pair RDDs\n",
        "\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "All transformations applied to standard RDDs can be applied to Pair RDDs as well. The only difference is that any function that is passed to a transformation or an action must take in pairs instead of single values.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "In addition, the following transformations can **only** be applied to Pair RDDs:\n",
        "<ol>\n",
        "<li> $r.reduceByKey(func)$. It applies the given function $func$ pairwise to all elements of the input RDD $r$ that are associated to the same key. \n",
        "<li> $r.sortBy(func, asc)$. Returns an RDD where the elements of the input RDD $r$ are sorted according to the given criteria.\n",
        "<li> $r.groupByKey()$. Groups the values of the input RDD $r$ association to the same key.\n",
        "<li> $r.keys()$. Returns an RDD where the elements are the keys from the input RDD $r$.\n",
        "<li> $r.values()$. Returns an RDD where the elements are the values from the input RDD $r$.\n",
        "<li> $r.join(r1)$. Joins the values of the two RDDs $r$ and $r_1$ that have the same key.\n",
        "</ol>\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<hr style=\" border:solid 2px;\">\n",
        "<p>\n",
        "<font size=\"3\" color='#91053d'><strong>Execute the following code and the read the comments in the code to understand these transformations.</strong></font>\n",
        "</p>\n",
        "<hr style=\" border:solid 2px;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jpYqHqeR6aJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb8ce4e-55a8-4372-ec16-c5cbe5c87d94"
      },
      "source": [
        "'''\n",
        "Create a RDD, where each item is a string s.\n",
        "'''\n",
        "sample_rdd = sc.parallelize(['do', 'you', 'enjoy', 'this', 'exercise', '?', 'yes', 'I', 'hope'])\n",
        "\n",
        "'''\n",
        "Transform the sample_rdd into one, where each item is (len(s), s)\n",
        "'''\n",
        "sample_rdd = sample_rdd.map(lambda x: (len(x), x))\n",
        "print(\"Key-value pairs\", sample_rdd.collect())\n",
        "\n",
        "'''\n",
        "Transform the previous rdd into one where items are sorted by key in descending order.\n",
        "In the following instruction, x represents an item of the input RDD (a tuple (len(s), s)),\n",
        "x[0] denotes the first element in the tuple (that is, len(s)).\n",
        "'''\n",
        "\n",
        "sample_rdd = sample_rdd.sortBy(lambda x: x[0], ascending=False)\n",
        "print(\"\\nOrdered key-value pairs\", sample_rdd.collect())\n",
        "\n",
        "'''\n",
        "Group items by key by using \n",
        "groupByKey(). \n",
        "The result is a RDD, where each item is (k, L), k is an integer, L is an iterable, \n",
        "an object that allows one to iterate over a list.\n",
        "'''\n",
        "sample_rdd_gbk = sample_rdd.groupByKey()\n",
        "print(\"\\nGroup by key\", sample_rdd_gbk.collect())\n",
        "\n",
        "'''\n",
        "Alternatively, grouping by key can also be achieved with the two following instructions.\n",
        "The result, however, will be a RDD, where each item is (k, L), k is an integer and \n",
        "L is a list (not an iterable as before). \n",
        "'''\n",
        "# The following instruction transforms each tuple (len(s), s) of the input RDD into a tuple\n",
        "# (len(s), [s]); the second element of the tuple becomes a list.\n",
        "sample_rdd_gbk_alternative = sample_rdd.map(lambda x: (x[0], [x[1]]))\n",
        "\n",
        "# \n",
        "# Given two tuples of the input RDD (len(s1), [s1]) and (len(s2), [s2]), \n",
        "# in the following instruction x and y are [s1] and [s2] respectively. \n",
        "# The instruction x + y concatenate the two lists \n",
        "# [s1] and [s2], which gives the list [s1, s2].\n",
        "\n",
        "sample_rdd_gbk_alternative = sample_rdd_gbk_alternative.reduceByKey(lambda x, y: x+y)\n",
        "print(\"\\nAlternative group by key\", sample_rdd_gbk_alternative.collect())\n",
        "\n",
        "'''\n",
        "Obtain a RDDcontaining the keys of the RDD sample_rdd_gbk_alternative.\n",
        "'''\n",
        "keys = sample_rdd_gbk_alternative.keys()\n",
        "print(\"\\nKeys\", keys.collect())\n",
        "\n",
        "'''\n",
        "Obtain a RDD containing the values  of the RDD sample_rdd_gbk_alternative.\n",
        "'''\n",
        "values = sample_rdd_gbk_alternative.values()\n",
        "print(\"\\nValues\", values.collect())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key-value pairs [(2, 'do'), (3, 'you'), (5, 'enjoy'), (4, 'this'), (8, 'exercise'), (1, '?'), (3, 'yes'), (1, 'I'), (4, 'hope')]\n",
            "\n",
            "Ordered key-value pairs [(8, 'exercise'), (5, 'enjoy'), (4, 'this'), (4, 'hope'), (3, 'you'), (3, 'yes'), (2, 'do'), (1, '?'), (1, 'I')]\n",
            "\n",
            "Group by key [(8, <pyspark.resultiterable.ResultIterable object at 0x7fd50cc008d0>), (5, <pyspark.resultiterable.ResultIterable object at 0x7fd50cc00910>), (4, <pyspark.resultiterable.ResultIterable object at 0x7fd50cbd8b90>), (3, <pyspark.resultiterable.ResultIterable object at 0x7fd50cc00a10>), (2, <pyspark.resultiterable.ResultIterable object at 0x7fd50cc00290>), (1, <pyspark.resultiterable.ResultIterable object at 0x7fd50cc00650>)]\n",
            "\n",
            "Alternative group by key [(8, ['exercise']), (5, ['enjoy']), (4, ['this', 'hope']), (3, ['you', 'yes']), (2, ['do']), (1, ['?', 'I'])]\n",
            "\n",
            "Keys [8, 5, 4, 3, 2, 1]\n",
            "\n",
            "Values [['exercise'], ['enjoy'], ['this', 'hope'], ['you', 'yes'], ['do'], ['?', 'I']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqqk0vR76aJ3"
      },
      "source": [
        "### The transformation join\n",
        "\n",
        "Let $r1$ and $r_2$ two pair RDDs. \n",
        "If $(k, v1)$ and $(k, v2)$ are two elements of $r_1$ and $r_2$ respectively, \n",
        "the result of $r1.join(r2)$ contains the pair $(k, (v1, v2))$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-GamaxI6aJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc1f703-0ba4-429e-eb72-65bff572c101"
      },
      "source": [
        "r1 = sc.parallelize([('first', 1), ('second', 2), ('third', 3)])\n",
        "r2 = sc.parallelize([('first', 2), ('second', 4), ('third', 9)])\n",
        "\n",
        "rdd_join = r1.join(r2)\n",
        "rdd_join.collect()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('third', (3, 9)), ('first', (1, 2)), ('second', (2, 4))]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "autoscroll": "json-false",
        "collapsed": true,
        "ein.tags": [
          "worksheet-0"
        ],
        "id": "yh8d3UNb6aJ4"
      },
      "source": [
        "<hr style=\" border:solid 2px;\">\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "An elegant way to write a sequence of transformations is shown in the following \n",
        "code. \n",
        "The tranformations are chained one after the other; each line contains a transformation.\n",
        "The symbol \"\\\" indicates that the Python instruction continues in the following line.\n",
        "We recommend you to use this style in the exercises that you'll be asked to \n",
        "do later.\n",
        "</font>\n",
        "</p>\n",
        "<hr style=\" border:solid 2px;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiNIMjXk6aJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87264490-7e93-4cf0-e71e-492931816c30"
      },
      "source": [
        "'''\n",
        "Create a RDD, where each item is a string s.\n",
        "'''\n",
        "sample_rdd = sc.parallelize(['do', 'you', 'enjoy', 'this', 'exercise', '?', 'yes', 'I', 'hope'])\\\n",
        "                .map(lambda x: (len(x), x))\\\n",
        "                .map(lambda x: (x[0], [x[1]]))\\\n",
        "                .reduceByKey(lambda x, y: x+y)\\\n",
        "                .sortBy(lambda x: x[0], ascending=False)\n",
        "\n",
        "sample_rdd.collect()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(8, ['exercise']),\n",
              " (5, ['enjoy']),\n",
              " (4, ['this', 'hope']),\n",
              " (3, ['you', 'yes']),\n",
              " (2, ['do']),\n",
              " (1, ['?', 'I'])]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqRPyKhr6aJ6"
      },
      "source": [
        "## B.3 Actions on Pair RDDs\n",
        "\n",
        "<p justify=\"align\">\n",
        "<font size=\"3\">\n",
        "As with the transformations, all actions available for standard RDDs can be used on Pair RDDs as well.\n",
        "In addition, the following actions can be performed on Pair RDDs:\n",
        "<ol>\n",
        "<li> $countByKey()$. Returns a Python dictionary, where each key is mapped to the number of values associated to that key.\n",
        "<li> $collectAsMap()$. Collects the RDD as a dictionary (in the same way as the function $collect()$ returns a list from a standard RDD).\n",
        "<li> $lookup(key)$. Returns a list with all the values associated with the given _key_.\n",
        "</ol>\n",
        "</font>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDqQdiUU6aJ7"
      },
      "source": [
        "# Exercises \n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "In the following exercises, you'll have to use RDD transformations/actions to implement some computations.\n",
        "</font>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQsCKkbLfYae"
      },
      "source": [
        "## 1 - Processing Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGgqHoUE6aJ7"
      },
      "source": [
        "<hr style=\"border:solid 2px;\">\n",
        "\n",
        "###  Exercise 1.1 - Creating an RDD\n",
        "\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Write the code to create an RDD from the input text file './data/moby-dick.txt' .\n",
        "</font>\n",
        "</p>\n",
        "<hr style=\"border:solid 2px;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpbYLc7v6aJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be3740b-695b-4e6b-bf39-c96c0d735171"
      },
      "source": [
        "'''\n",
        "Loads a text file in RDD\n",
        "\n",
        "INPUT:\n",
        "        the filename\n",
        "\n",
        "\n",
        "'''\n",
        "def load_text(filename):\n",
        "    return sc.textFile(filename)\n",
        "\n",
        "\n",
        "mobydick = load_text('moby-dick.txt')\n",
        "print(\"If the execution arrives there probably you loaded the file in a RDD\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If the execution arrives there probably you loaded the file in a RDD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vflg0cuZcjR7"
      },
      "source": [
        "\n",
        "###  Utility functions\n",
        "\n",
        "Here we provide some utility functions that will be usefull to read and to pre-process a file. \n",
        "\n",
        "\n",
        "\n",
        "*   <code> remove_non_letters(word)</code> takes as input a word and removes any character that is not a letter.\n",
        "*   <code> load_stopwords(words) </code> reads a file that contains the stopwords and returns them in a <code>list</code>.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW0nzNS96aJ9"
      },
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# Regular expression for removing all non-letter characters in the file.\n",
        "regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "'''\n",
        "Removes any non-letter character from the given word.\n",
        "\n",
        "INPUT:\n",
        "        word: A word\n",
        "\n",
        "OUTPUT:\n",
        "        the input word without the non-letter characters.\n",
        "\n",
        "'''\n",
        "def remove_non_letters(word):\n",
        "    return regex.sub('', word)\n",
        "\n",
        "\n",
        "'''\n",
        "INPUT: \n",
        "        stopwords_file: name of the file containing the stopwords.\n",
        "OUTPUT:\n",
        "        a Python list with the stopwords read from the file.\n",
        "'''\n",
        "def load_stopwords(stopwords_file):\n",
        "    stopwords = []\n",
        "    with open(stopwords_file) as file:\n",
        "        for sw in file:\n",
        "            stopwords.append(sw.strip())\n",
        "    return stopwords\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXDzNzFx6aJ9"
      },
      "source": [
        "<hr style=\"border:solid 2px;\">\n",
        "\n",
        "###  Exercise 1.2  - Preprocessing\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "We want to code a function $preprocess()$ that takes in the content of a text file, filters out useless words and\n",
        "returns the remaining words.\n",
        "This function has the following input and output:\n",
        "<ul>\n",
        " <li> INPUT: A RDD $text$, where each element is a line of a text file, and a Python list $stopwords$ that \n",
        "      contains the most common English *stopwords* (e.g., 'the', 'in', 'of'), that only serve a grammatical purpose, while adding little or no meaning to the other words in the file.\n",
        "<li> OUTPUT: A RDD, where each element is a word.\n",
        "</ul>\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\" color='#91053d'>\n",
        "<strong>Complete the code of the function $preprocess()$ with the following steps:</strong>\n",
        "<ol>\n",
        "<li>    Split each line into its constituent words (Python has a function $split$).\n",
        "<li>    Eliminate non-letter characters from each word.\n",
        "<li>    Filter out empty words (words with length 0).\n",
        "<li>    Lowercase all words (Python has a function $lower$).\n",
        "<li>    Remove the stopwords.\n",
        "</ol>\n",
        "<ul>\n",
        "<li> <strong>IMPORTANT:</strong> only use RDD transformations/actions, which guarantees that the computation will be distributed.\n",
        "<li> At the bottom of the next cell, you'll find the expected output, so you'll know if your implementation is correct. 👍🏻\n",
        "</ul>\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<hr style=\"border:solid 2px;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CriVBlChbhTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac5110a7-69f6-4d9c-fe67-5090d41ee9d9"
      },
      "source": [
        "'''\n",
        "INPUT: \n",
        "        text: RDD where each element is a line of the input text file.\n",
        "        stopwords: Python list containing the stopwords.\n",
        "OUTPUT: \n",
        "        RDD where each element is a word from the input text file.\n",
        "'''\n",
        "def preprocess(text, stopwords) :\n",
        "    ############## WRITE YOUR CODE HERE ##############\n",
        "    words = text.flatMap(lambda line: line.split(\" \"))\\\n",
        "              .map(lambda word: remove_non_letters(word))\\\n",
        "              .filter(lambda word: len(word) > 0).map(lambda word: word.lower())\\\n",
        "              .filter(lambda word: word not in stopwords)\n",
        "    return words\n",
        "\n",
        "stopwords = load_stopwords(\"stopwords.txt\")\n",
        "words = preprocess(mobydick, stopwords)\n",
        "words.takeOrdered(10, key = lambda x: x)\n",
        "\n",
        "################# EXPECTED OUTPUT #################\n",
        "#\n",
        "# ['aback',\n",
        "# 'aback',\n",
        "# 'abaft',\n",
        "# 'abaft',\n",
        "# 'abandon',\n",
        "# 'abandon',\n",
        "# 'abandon',\n",
        "# 'abandoned',\n",
        "# 'abandoned',\n",
        "# 'abandoned']\n",
        "#\n",
        "###################################################"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aback',\n",
              " 'aback',\n",
              " 'abaft',\n",
              " 'abaft',\n",
              " 'abandon',\n",
              " 'abandon',\n",
              " 'abandon',\n",
              " 'abandoned',\n",
              " 'abandoned',\n",
              " 'abandoned']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fGbui0-6aJ_"
      },
      "source": [
        "<hr style=\"border:solid 2px;\">\n",
        "\n",
        "###  Exercise 1.3 - Word count\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "We want to write the code of the function $word\\_count$ that counts the number of occurrences of each word in a text file.\n",
        "The function has the following input and output:\n",
        "<ul>\n",
        "<li> INPUT: A RDD $words$, where each element is a word from a text file $d$ (pre-processing already done).\n",
        "<li> OUTPUT: A RDD, where each element is $(w, f_{w, d})$, $w$ being a word and $f_{w, d}$ being the number of times $w$ appears in $d$. The output RDD must be sorted by $f_{w, d}$ in decreasing order.\n",
        "</ul>\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\" color='#91053d'>\n",
        "<strong>Write the code of the function $word\\_count()$.</strong>\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<hr style=\"border:solid 2px;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WlplKBu6aJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851e0b8c-5605-4cc9-f4f8-f67cb182d052"
      },
      "source": [
        "'''\n",
        "INPUT:\n",
        "        words: RDD, where each element is word from the input text file (preprocessing already done!).\n",
        "OUTPUT:\n",
        "        RDD, where each element is (w, occ), w is a word and occ the number of occurrences of w.\n",
        "        The RDD is sorted by value in decreasing order.\n",
        "'''\n",
        "def word_count(words):\n",
        "    ############## WRITE YOUR CODE HERE ##############'''\n",
        "    occs = words.map(lambda word: (word, 1))\\\n",
        "                .reduceByKey(lambda x, y: x+y)\\\n",
        "                .sortBy(lambda f: f[1], ascending=False)\n",
        "    return occs\n",
        "\n",
        "occs = word_count(words)\n",
        "occs.take(5)\n",
        "\n",
        "################# EXPECTED OUTPUT #################\n",
        "#\n",
        "# [('whale', 891), ('one', 875), ('old', 436), ('man', 433), ('ahab', 417)]\n",
        "#\n",
        "###################################################\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('whale', 891), ('one', 875), ('old', 436), ('man', 433), ('ahab', 417)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95p6rC1ffDxw"
      },
      "source": [
        "## - 2 Bigrams\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "What is a Bigram? In our example a bigram is a couple of \n",
        "two consecutive words in a same line. \n",
        "    \n",
        "\n",
        "For example, the previous sentence contains the following bigrams: \"A bigram\", \"bigram is\", \"is a\", \"a couple\", etc.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "This exercise can be seen as a simple extension of the word count, take into account this while implementing your data structures and your code. \n",
        "</font>\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "As first step here is the to create a new RDD from the input text file './data/moby-dick.txt' that we already used in the first series of the exercises.\n",
        "</font>\n",
        "</p>\n",
        "<hr style=\"border:solid 2px;\">\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "We provide then a possible implementation of a function that reads the document and give as output the list of bigram in the text. \n",
        "\n",
        "<ul>\n",
        "<li> INPUT: A RDD, where each element is a line from a text file $d$ (pre-processing already done).\n",
        "<li> OUTPUT: A list, where each element $(w1, w2)$ is a bigram.\n",
        "</ul>\n",
        "\n",
        "For this exercise we will focus at line level: a bigram can't be on two different lines (even if we did not put a full stop before). You can add more accurate analysis of the text and of the sentences (at syntactical and semantical level) if you want to play with coding.\n",
        "\n",
        "Feel free to re-implement your read function if you want to use a different data-structure.\n",
        "</font>\n",
        "</p>\n",
        "<hr style=\"border:solid 2px;\">\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foyxsWrYhg3Z"
      },
      "source": [
        "from operator import add\n",
        "\n",
        "'''\n",
        "Returns the list of bigrams in a given text for each line (the end of a bigram search space is a line\n",
        "of text:\n",
        "\"This  sentence\n",
        "contains two different lines for looking for bigrams.\"\n",
        "INPUT:\n",
        "        a line of a text\n",
        "\n",
        "OUTPUT:\n",
        "        a list of bigrams for the text of the form b1_b2 where \"b1_b2\" is a string.\n",
        "\n",
        "'''\n",
        "\n",
        "def parse_bigrams(line):\n",
        "    bigrams = []\n",
        "    words = line.strip().split(\" \")\n",
        "    for i in range(len(words) - 1):\n",
        "        bigram_w1 = remove_non_letters(words[i].lower()) \n",
        "        bigram_w2 = remove_non_letters(words[i+1].lower())\n",
        "        if (len(bigram_w1) > 0) & (len(bigram_w2) > 0) :\n",
        "                bigrams.append(bigram_w1 + \"_\" + bigram_w2)\n",
        "    return bigrams"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THFVYrXXhlXD"
      },
      "source": [
        "### Exercise 2.1 - MapReduce\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Describe MapReduce procedure that gives as output the number of different bigrams that appear all along the document (if the bigram \"is a\" appears twice in the document must be counted just one time).\n",
        "\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vcXtS8KknNH"
      },
      "source": [
        "#Describe here your algorithm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdbQen5uiKde"
      },
      "source": [
        "### Exercise 2.2 - Implementation\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Propose a Spark implementation of your procedure that follows a map-reduce approach.\n",
        "</font>\n",
        "</p> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGs4-qesiSNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a94d7399-6833-4e2a-e65b-d12b0a6ae045"
      },
      "source": [
        "'''\n",
        "Write here a procedure that \n",
        "\n",
        "INPUT:\n",
        "        an RDD containing strings representing words\n",
        "\n",
        "OUTPUT:\n",
        "        the number of distinct bigrams.\n",
        "\n",
        "flatMap  .....\n",
        "\n",
        "map .... \n",
        "\n",
        "reduce ....\n",
        "\n",
        "''' \n",
        "\n",
        "'''############## WRITE YOUR CODE HERE ##############'''\n",
        "\n",
        "counts = mobydick.flatMap(parse_bigrams)\\\n",
        "                 .map(lambda x: (x,1))\\\n",
        "                 .reduceByKey(lambda x,y: x+y)\n",
        "output = counts.collect()\n",
        "    \n",
        "    \n",
        "'''############## END OF THE EXERCISE ##############'''\n",
        " \n",
        "\n",
        "\n",
        "print(counts.take(5))\n",
        "print(counts.count())\n",
        "\n",
        "################# EXPECTED OUTPUT #################\n",
        "#\n",
        "# [('call_me', 3), ('me_ishmael', 1), ('some_years', 1), ('years_agonever', 1), ('agonever_mind', 1)]\n",
        "# 100513\n",
        "###################################################"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('call_me', 3), ('me_ishmael', 1), ('some_years', 1), ('years_agonever', 1), ('agonever_mind', 1)]\n",
            "100513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x04YbBdicj7"
      },
      "source": [
        "### Exercise 2.3 - Smart parsing of bigrams\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Sometimes when you write functions you do not realize that you can use a MapReduce series of steps.\n",
        "Look at the provided function that parses bigrams and outputs a string representation of them. Re-think the functions using map, reduce, and filter operators,\n",
        "    in Spark.\n",
        "    </font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Propose a Spark implementation of the procedure  that follows a map-reduce approach, parses lines of text, and \n",
        "gives as output pairs of strings representing bigrams. For this step you just can to re-use the\n",
        " functions we already studied, for example:\n",
        "<ul>\n",
        "    <li> map() </li>\n",
        "    <li> flatMap() </li>\n",
        "    <li> filter() </li>\n",
        "</ul>\n",
        "\n",
        "Notice that you can be more flexible in the structure of the \n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVJDb7JdipaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b13966-f44c-4da3-bbf8-1c31e309d93c"
      },
      "source": [
        "'''\n",
        "Returns a list of pairs of strings representing bigrams in a given text.\n",
        "The procedure returns bigrams for each line (the search space of the bigrams is a line of text):\n",
        "\"This  sentence\n",
        "contains two different lines and ('sentence','contains') is not in the output.\"\n",
        "INPUT:\n",
        "        a line of a text\n",
        "\n",
        "OUTPUT:\n",
        "        a list of pairs bigrams for the text of the form (b1, b2) where ('b1', 'b2')\" is a pair of strings.\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "'''############## WRITE YOUR CODE HERE ##############'''\n",
        "def parse_smart_parse_bigrams(text_rdd):\n",
        "    bigrams = text_rdd.map(lambda line: line.split(\" \")) \\\n",
        "                   .flatMap(lambda xs: (tuple(x) for x in zip(xs, xs[1:])))\\\n",
        "                   .map(lambda x : (remove_non_letters(x[0].lower()), remove_non_letters(x[1].lower())))\\\n",
        "                   .filter(lambda x : len(x[0]) > 0 and len(x[1]) > 0)\n",
        "    return bigrams\n",
        "'''############## END OF THE EXERCISE ##############'''\n",
        "\n",
        "\n",
        "\n",
        "bigrams=parse_smart_parse_bigrams(mobydick)\n",
        "result = bigrams.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "print(result.count())\n",
        "print(result.take(100))\n",
        "\n",
        "################# EXPECTED OUTPUT #################\n",
        "#\n",
        "#  100513\n",
        "#[(('call', 'me'), 3), (('me', 'ishmael'), 1), (('some', 'years'), 1), (('years', 'agonever'), 1), (('agonever', 'mind'), 1), (('mind', 'how'), 6), (('how', 'long'), 7), (('preciselyhaving', 'little'), 1), (('little', 'or'), 6), (('or', 'no'), 6), (('no', 'money'), 1), (('money', 'in'), 3), (('in', 'my'), 46), (('my', 'purse'), 1), (('purse', 'and'), 1), (('and', 'nothing'), 6), (('particular', 'to'), 2), (('to', 'interest'), 1), (('interest', 'me'), 1), (('me', 'on'), 8), (('on', 'shore'), 3), (('shore', 'i'), 1), (('i', 'thought'), 38), (('thought', 'i'), 31), (('i', 'would'), 30), (('would', 'sail'), 1), (('sail', 'about'), 2), (('about', 'a'), 12), (('little', 'and'), 3), (('and', 'see'), 9), (('see', 'the'), 23), (('the', 'watery'), 14), (('watery', 'part'), 1), (('part', 'of'), 89), (('of', 'the'), 1726), (('the', 'world'), 68), (('it', 'is'), 263), (('is', 'a'), 109), (('a', 'way'), 4), (('way', 'i'), 1), (('i', 'have'), 107), (('have', 'of'), 2), (('driving', 'off'), 1), (('off', 'the'), 31), (('the', 'spleen'), 1), (('spleen', 'and'), 1), (('and', 'regulating'), 1), (('regulating', 'the'), 1), (('the', 'circulation'), 1), (('whenever', 'i'), 4), (('find', 'myself'), 2), (('myself', 'growing'), 1), (('growing', 'grim'), 1), (('grim', 'about'), 1), (('about', 'the'), 55), (('the', 'mouth'), 10), (('mouth', 'whenever'), 1), (('whenever', 'it'), 2), (('a', 'damp'), 1), (('drizzly', 'november'), 1), (('november', 'in'), 1), (('my', 'soul'), 16), (('soul', 'whenever'), 1), (('i', 'find'), 3), (('myself', 'involuntarily'), 1), (('pausing', 'before'), 2), (('before', 'coffin'), 1), (('coffin', 'warehouses'), 1), (('warehouses', 'and'), 1), (('and', 'bringing'), 3), (('bringing', 'up'), 2), (('up', 'the'), 47), (('the', 'rear'), 10), (('rear', 'of'), 2), (('of', 'every'), 10), (('funeral', 'i'), 1), (('i', 'meet'), 2), (('meet', 'and'), 1), (('and', 'especially'), 10), (('especially', 'whenever'), 1), (('whenever', 'my'), 1), (('my', 'hypos'), 1), (('hypos', 'get'), 1), (('get', 'such'), 1), (('such', 'an'), 31), (('an', 'upper'), 1), (('hand', 'of'), 6), (('of', 'me'), 13), (('me', 'that'), 36), (('that', 'it'), 49), (('it', 'requires'), 2), (('requires', 'a'), 2), (('a', 'strong'), 8), (('strong', 'moral'), 1), (('moral', 'principle'), 1), (('principle', 'to'), 1), (('to', 'prevent'), 4), (('prevent', 'me'), 1), (('from', 'deliberately'), 1), (('deliberately', 'stepping'), 1)]\n",
        "###################################################"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100513\n",
            "[(('call', 'me'), 3), (('me', 'ishmael'), 1), (('some', 'years'), 1), (('years', 'agonever'), 1), (('agonever', 'mind'), 1), (('mind', 'how'), 6), (('how', 'long'), 7), (('preciselyhaving', 'little'), 1), (('little', 'or'), 6), (('or', 'no'), 6), (('no', 'money'), 1), (('money', 'in'), 3), (('in', 'my'), 46), (('my', 'purse'), 1), (('purse', 'and'), 1), (('and', 'nothing'), 6), (('particular', 'to'), 2), (('to', 'interest'), 1), (('interest', 'me'), 1), (('me', 'on'), 8), (('on', 'shore'), 3), (('shore', 'i'), 1), (('i', 'thought'), 38), (('thought', 'i'), 31), (('i', 'would'), 30), (('would', 'sail'), 1), (('sail', 'about'), 2), (('about', 'a'), 12), (('little', 'and'), 3), (('and', 'see'), 9), (('see', 'the'), 23), (('the', 'watery'), 14), (('watery', 'part'), 1), (('part', 'of'), 89), (('of', 'the'), 1726), (('the', 'world'), 68), (('it', 'is'), 263), (('is', 'a'), 109), (('a', 'way'), 4), (('way', 'i'), 1), (('i', 'have'), 107), (('have', 'of'), 2), (('driving', 'off'), 1), (('off', 'the'), 31), (('the', 'spleen'), 1), (('spleen', 'and'), 1), (('and', 'regulating'), 1), (('regulating', 'the'), 1), (('the', 'circulation'), 1), (('whenever', 'i'), 4), (('find', 'myself'), 2), (('myself', 'growing'), 1), (('growing', 'grim'), 1), (('grim', 'about'), 1), (('about', 'the'), 55), (('the', 'mouth'), 10), (('mouth', 'whenever'), 1), (('whenever', 'it'), 2), (('a', 'damp'), 1), (('drizzly', 'november'), 1), (('november', 'in'), 1), (('my', 'soul'), 16), (('soul', 'whenever'), 1), (('i', 'find'), 3), (('myself', 'involuntarily'), 1), (('pausing', 'before'), 2), (('before', 'coffin'), 1), (('coffin', 'warehouses'), 1), (('warehouses', 'and'), 1), (('and', 'bringing'), 3), (('bringing', 'up'), 2), (('up', 'the'), 47), (('the', 'rear'), 10), (('rear', 'of'), 2), (('of', 'every'), 10), (('funeral', 'i'), 1), (('i', 'meet'), 2), (('meet', 'and'), 1), (('and', 'especially'), 10), (('especially', 'whenever'), 1), (('whenever', 'my'), 1), (('my', 'hypos'), 1), (('hypos', 'get'), 1), (('get', 'such'), 1), (('such', 'an'), 31), (('an', 'upper'), 1), (('hand', 'of'), 6), (('of', 'me'), 13), (('me', 'that'), 36), (('that', 'it'), 49), (('it', 'requires'), 2), (('requires', 'a'), 2), (('a', 'strong'), 8), (('strong', 'moral'), 1), (('moral', 'principle'), 1), (('principle', 'to'), 1), (('to', 'prevent'), 4), (('prevent', 'me'), 1), (('from', 'deliberately'), 1), (('deliberately', 'stepping'), 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jiFbrHpiqrB"
      },
      "source": [
        "### Exercise 2.4 - Bigrams search\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Look at the two procedures that parse bigrams and provide the output in two different format: is the type of the\n",
        "   key influencing the map-reduce procedure? </font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "From the performances point of view which data representation is better according to your opinion? Explain and motivate your answer\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDdC2r7Qi1Vc"
      },
      "source": [
        "#Also in distributed context you have to consider:\n",
        "#1) computation performance \n",
        "#2) space issues\n",
        "#3) data representation\n",
        "#4) code mantainance\n",
        "#5) cluster configuration\n",
        "#and think and run experiment about the better solution playing with spark configuration, data representation and code.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrZDRVeqi4NM"
      },
      "source": [
        "### Exercise 2.5 - Most common bigrams\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Now that we start being confident with bigrams and MapReduce, we can start analysing the bigrams and write a procedure that gives as output the top 5 most common bigrams that appear all along the document.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Propose a Spark implementation of your procedure that transfomrs the key-value pairs and uses the top operation\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Spg0AXai9nC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19749604-436d-46b1-9768-1fd6821cd53b"
      },
      "source": [
        "'''############## WRITE YOUR CODE HERE ##############'''\n",
        "inverted_result = result.map(lambda a: (a[1],a[0]))\n",
        "rw_result = bigrams.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y).sortBy(lambda f: f[1], ascending=False)\n",
        "ri_result = result.takeOrdered ( 10, key = lambda x : -x[1] )\n",
        "'''############## END OF THE EXERCISE ##############'''\n",
        "\n",
        "print(rw_result.take(5))\n",
        "print(inverted_result.top(5))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################# EXPECTED OUTPUT #################\n",
        "#\n",
        "# [(1726, ('of', 'the')), (1078, ('in', 'the')), (674, ('to', 'the')), (404, ('from', 'the')), (348, ('and', 'the'))]\n",
        "###################################################"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('of', 'the'), 1726), (('in', 'the'), 1078), (('to', 'the'), 674), (('from', 'the'), 404), (('and', 'the'), 348)]\n",
            "[(('of', 'the'), 1726), (('in', 'the'), 1078), (('to', 'the'), 674), (('from', 'the'), 404), (('and', 'the'), 348)]\n",
            "[(1726, ('of', 'the')), (1078, ('in', 'the')), (674, ('to', 'the')), (404, ('from', 'the')), (348, ('and', 'the'))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIHxp0lOjBDe"
      },
      "source": [
        "### Exercise 2.6 - Unique bigrams\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Try to re-use some of the steps you implemented in the previous exercise and provide the functions that counts the bigrams that appear only once in the text (if the bigram \"is a\" appears twice in the text it must not be counted in the final result).\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CQqyU2ljE5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf79bad-1a85-4bdb-8e79-9626ba186bd3"
      },
      "source": [
        "'''############## WRITE YOUR CODE HERE ##############'''\n",
        "\n",
        "\n",
        "unique_bigrams = inverted_result.filter(lambda a : a[0] ==1)\n",
        "\n",
        "\n",
        "'''############## END OF THE EXERCISE ##############'''\n",
        "\n",
        "\n",
        "print(unique_bigrams.take(5))\n",
        "\n",
        "################# EXPECTED OUTPUT #################\n",
        "#\n",
        "#[(1, ('me', 'ishmael')), (1, ('preciselyhaving', 'little')), (1, ('no', 'money')), (1, ('way', 'i')), (1, ('driving', 'off'))]###################################################"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, ('me', 'ishmael')), (1, ('some', 'years')), (1, ('years', 'agonever')), (1, ('agonever', 'mind')), (1, ('preciselyhaving', 'little'))]\n"
          ]
        }
      ]
    }
  ]
}